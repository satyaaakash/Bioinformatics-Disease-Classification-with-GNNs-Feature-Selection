{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48cd8639-796d-4e90-b9d7-864b1606c61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import io  # Use io.StringIO instead of pandas.compat.StringIO\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "611036d7-103e-45b2-8db9-71b76c807bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_target_labels_for_luekemia_dataset(file_path, metadata_key=\"subtype\"):\n",
    "    \"\"\"\n",
    "    Extract target labels from the multiple '!Sample_characteristics_ch1' lines in the Series Matrix file.\n",
    "    - file_path: Path to the Series Matrix file.\n",
    "    - metadata_key: Key to extract (e.g., 'subtype').\n",
    "    Returns:\n",
    "        A list of labels for each sample.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Find all lines with '!Sample_characteristics_ch1'\n",
    "    target_lines = [line for line in lines if line.startswith(\"!Sample_characteristics_ch1\")]\n",
    "    \n",
    "    # Look for the line containing the specified metadata key\n",
    "    key_line = next((line for line in target_lines if metadata_key in line), None)\n",
    "    \n",
    "    if not key_line:\n",
    "        raise ValueError(f\"The metadata key '{metadata_key}' was not found in any '!Sample_characteristics_ch1' line.\")\n",
    "    \n",
    "    # Extract relevant labels from the key line\n",
    "    labels = key_line.strip().split(\"\\t\")[1:]  # Skip the first column\n",
    "    target_labels = [label.split(\":\")[-1].strip().replace('\"', '') for label in labels]\n",
    "    \n",
    "    return target_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7648290e-0b5b-4a6e-8f1b-d3be8eff88b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_target_labels_for_lung_dataset(file_path, metadata_key=\"tissue\"):\n",
    "    \"\"\"\n",
    "    Extract target labels from the '!Sample_characteristics_ch1' line in the Series Matrix file.\n",
    "    - file_path: Path to the Series Matrix file.\n",
    "    - metadata_key: Key to extract (e.g., 'tissue').\n",
    "    Returns:\n",
    "        A list of labels for each sample.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Find the line with '!Sample_characteristics_ch1'\n",
    "    target_line = next((line for line in lines if line.startswith(\"!Sample_characteristics_ch1\")), None)\n",
    "    print(target_line)\n",
    "    \n",
    "    if not target_line:\n",
    "        raise ValueError(\"The '!Sample_characteristics_ch1' metadata line was not found in the file.\")\n",
    "    \n",
    "    # Extract relevant labels from the target line\n",
    "    labels = target_line.strip().split(\"\\t\")[1:]  # Skip the first column\n",
    "    target_labels = []\n",
    "    for label in labels:\n",
    "        # Extract the value corresponding to the metadata key\n",
    "        if metadata_key in label:\n",
    "            extracted_label = label.split(\":\")[-1].strip().replace('\"', '')\n",
    "            target_labels.append(extracted_label)\n",
    "    \n",
    "    return target_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e57c552-00a7-4600-9202-f4076cf39357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_target_labels_for_tumor_dataset(file_path, metadata_key=\"Histopathological diagnostic\"):\n",
    "    \"\"\"\n",
    "    Extract specific target labels (e.g., astrocytoma, glioblastoma, oligodendroglioma) from\n",
    "    the '!Sample_characteristics_ch1' line in the Series Matrix file.\n",
    "    - file_path: Path to the Series Matrix file.\n",
    "    - metadata_key: Key to extract (e.g., 'Histopathological diagnostic').\n",
    "    Returns:\n",
    "        A list of labels for each sample.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Find the line with '!Sample_characteristics_ch1'\n",
    "    target_line = next((line for line in lines if line.startswith(\"!Sample_characteristics_ch1\")), None)\n",
    "    \n",
    "    if not target_line:\n",
    "        raise ValueError(\"The '!Sample_characteristics_ch1' metadata line was not found in the file.\")\n",
    "    \n",
    "    # Extract relevant labels from the target line\n",
    "    labels = target_line.strip().split(\"\\t\")[1:]  # Skip the first column\n",
    "    target_labels = []\n",
    "    for label in labels:\n",
    "        # Extract the value corresponding to the metadata key\n",
    "        if metadata_key in label:\n",
    "            extracted_label = label.split(\":\")[-1].strip().replace('\"', '').split(\",\")[0]  # Get the first part (e.g., astrocytoma)\n",
    "            target_labels.append(extracted_label)\n",
    "        else:\n",
    "            raise ValueError(f\"The metadata key '{metadata_key}' is not found in one or more entries.\")\n",
    "    \n",
    "    return target_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "813f1b7b-6fe8-46a5-878f-2b5aa26abc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_target_with_preprocessed(preprocessed_file, target_labels, output_file):\n",
    "    \"\"\"\n",
    "    Merge target labels with the preprocessed dataset.\n",
    "    - preprocessed_file: Path to the preprocessed CSV file.\n",
    "    - target_labels: List of target labels (one per sample).\n",
    "    - output_file: Path to save the merged dataset.\n",
    "    \"\"\"\n",
    "    # Load preprocessed data\n",
    "    preprocessed_data = pd.read_csv(preprocessed_file, index_col=0)  # Ensure Probe IDs are preserved as the index\n",
    "\n",
    "    # Transpose the dataset to make samples as rows\n",
    "    preprocessed_data = preprocessed_data.T\n",
    "    print(len(target_labels))\n",
    "    print(preprocessed_data.shape)\n",
    "\n",
    "    # Ensure the number of labels matches the number of samples (now rows after transposing)\n",
    "    if len(target_labels) != preprocessed_data.shape[0]:\n",
    "        raise ValueError(\"Number of target labels does not match the number of samples.\")\n",
    "\n",
    "    # Add target labels as a new column\n",
    "    preprocessed_data[\"Target\"] = target_labels\n",
    "\n",
    "    # Save the updated dataset\n",
    "    preprocessed_data.to_csv(output_file)\n",
    "    print(f\"Dataset with target labels saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6482a17e-596f-4251-8974-1039417d37d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_series_matrix(file_path):\n",
    "    \"\"\"\n",
    "    Load numeric data from a GEO Series Matrix file, ignoring metadata.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Skip metadata lines starting with \"!\" or \"^\"\n",
    "    data_lines = [line for line in lines if not line.startswith(\"!\") and not line.startswith(\"^\")]\n",
    "\n",
    "    # Join filtered lines and read into pandas DataFrame\n",
    "    df = pd.read_csv(\n",
    "        io.StringIO(\"\".join(data_lines)),\n",
    "        sep=\"\\t\",\n",
    "        index_col=0\n",
    "    )\n",
    "    \n",
    "    # Ensure numeric data\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    if numeric_df.empty:\n",
    "        raise ValueError(f\"The dataset {file_path} contains no numeric data after filtering.\")\n",
    "    \n",
    "    return numeric_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95e16dd6-1f38-474c-8553-cc909bf6f471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess the gene expression data:\n",
    "    - Remove rows/columns with too many missing values\n",
    "    - Impute missing values\n",
    "    - Normalize the data\n",
    "    \"\"\"\n",
    "    # Drop rows and columns with more than 50% missing values\n",
    "    df = df.dropna(axis=0, thresh=int(0.5 * df.shape[1]))\n",
    "    df = df.dropna(axis=1, thresh=int(0.5 * df.shape[0]))\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(\"All rows or columns were dropped due to missing values.\")\n",
    "    \n",
    "    # Impute missing values with the mean of each column\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    df_imputed = pd.DataFrame(imputer.fit_transform(df), index=df.index, columns=df.columns)\n",
    "    \n",
    "    # Normalize the data using Min-Max Scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    df_normalized = pd.DataFrame(scaler.fit_transform(df_imputed), index=df.index, columns=df.columns)\n",
    "    \n",
    "    return df_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a62f27b0-4cfa-46fd-91b0-193a39f71107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preprocessed_data(df, output_path):\n",
    "    \"\"\"\n",
    "    Save the preprocessed DataFrame to a CSV file.\n",
    "    \"\"\"\n",
    "    df.to_csv(output_path, index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2763f71d-fd1c-4de7-9202-2ebf0ba7d4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing E:/MS SUBJECTS/3rdSem/Bioinformatics/bioproject/datasets/GSE27562_series_matrix.txt...\n",
      "Data loaded successfully with shape: (54675, 162)\n",
      "Preprocessed data saved to preprocessed_datasets\\preprocessed_GSE27562_series_matrix.csv\n",
      "Processing E:/MS SUBJECTS/3rdSem/Bioinformatics/bioproject/datasets/GSE19804_series_matrix.txt...\n",
      "Data loaded successfully with shape: (54675, 120)\n",
      "Preprocessed data saved to preprocessed_datasets\\preprocessed_GSE19804_series_matrix.csv\n",
      "Processing E:/MS SUBJECTS/3rdSem/Bioinformatics/bioproject/datasets/GSE4290_series_matrix.txt...\n",
      "Data loaded successfully with shape: (54613, 180)\n",
      "Preprocessed data saved to preprocessed_datasets\\preprocessed_GSE4290_series_matrix.csv\n",
      "Processing E:/MS SUBJECTS/3rdSem/Bioinformatics/bioproject/datasets/GSE59856_series_matrix.txt...\n",
      "Data loaded successfully with shape: (2555, 571)\n",
      "Preprocessed data saved to preprocessed_datasets\\preprocessed_GSE59856_series_matrix.csv\n",
      "Processing E:/MS SUBJECTS/3rdSem/Bioinformatics/bioproject/datasets/GSE33315_series_matrix.txt...\n",
      "Data loaded successfully with shape: (22283, 575)\n",
      "Preprocessed data saved to preprocessed_datasets\\preprocessed_GSE33315_series_matrix.csv\n"
     ]
    }
   ],
   "source": [
    "def process_all_files(file_paths, output_dir):\n",
    "    \"\"\"\n",
    "    Preprocess multiple Series Matrix files and save the results.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            print(f\"Processing {file_path}...\")\n",
    "            # Load the data\n",
    "            data = load_series_matrix(file_path)\n",
    "\n",
    "            #print(data)\n",
    "            \n",
    "            # Remove non-numeric columns (e.g., metadata)\n",
    "            data_numeric = data.select_dtypes(include=[np.number])\n",
    "            if data_numeric.empty:\n",
    "                raise ValueError(f\"The dataset {file_path} contains no numeric data.\")\n",
    "            print(f\"Data loaded successfully with shape: {data_numeric.shape}\")\n",
    "\n",
    "           \n",
    "            \n",
    "            \n",
    "            # Preprocess the data\n",
    "            preprocessed_data = preprocess_data(data_numeric)\n",
    "            \n",
    "            # Generate output file name\n",
    "            output_file = os.path.join(output_dir, f\"preprocessed_{os.path.basename(file_path).replace('.txt', '.csv')}\")\n",
    "            \n",
    "            # Save preprocessed data\n",
    "            save_preprocessed_data(preprocessed_data, output_file)\n",
    "            \n",
    "            print(f\"Preprocessed data saved to {output_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "# List of files to process\n",
    "file_paths = [\n",
    "    \"E:/MS SUBJECTS/3rdSem/Bioinformatics/bioproject/datasets/GSE27562_series_matrix.txt\",\n",
    "    \"E:/MS SUBJECTS/3rdSem/Bioinformatics/bioproject/datasets/GSE19804_series_matrix.txt\",\n",
    "    \"E:/MS SUBJECTS/3rdSem/Bioinformatics/bioproject/datasets/GSE4290_series_matrix.txt\",\n",
    "    \"E:/MS SUBJECTS/3rdSem/Bioinformatics/bioproject/datasets/GSE59856_series_matrix.txt\",\n",
    "    \"E:/MS SUBJECTS/3rdSem/Bioinformatics/bioproject/datasets/GSE33315_series_matrix.txt\"\n",
    "]\n",
    "\n",
    "# Output directory for preprocessed files\n",
    "output_dir = \"preprocessed_datasets\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Process all datasets\n",
    "    process_all_files(file_paths, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cdd84c1-ac51-4145-9425-cf6d8c3e0103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting target labels...\n",
      "120\n",
      "Merging target labels with preprocessed data...\n",
      "Dataset with target labels saved to preprocessed/preprocessed_with_target_GSE19804.csv\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "series_matrix_path = \"datasets/GSE19804_series_matrix.txt\"\n",
    "preprocessed_file = \"preprocessed_datasets/preprocessed_GSE19804.csv\"\n",
    "output_file = \"preprocessed/preprocessed_with_target_GSE19804.csv\"\n",
    "\n",
    "# Process GSE19804\n",
    "metadata_key = \"tissue\"  # Key for the target variable\n",
    "print(\"Extracting target labels...\")\n",
    "target_labels = extract_target_labels(series_matrix_path, metadata_key)\n",
    "\n",
    "print(len(target_labels))\n",
    "\n",
    "print(\"Merging target labels with preprocessed data...\")\n",
    "merge_target_with_preprocessed(preprocessed_file, target_labels, output_file)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d73397a-a006-481c-bcd7-85b93c43a7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting target labels...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'extract_target_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m metadata_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtissue\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Key for the target variable\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting target labels...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m target_labels \u001b[38;5;241m=\u001b[39m extract_target_labels(series_matrix_path, metadata_key)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(target_labels))\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMerging target labels with preprocessed data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_target_labels' is not defined"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "series_matrix_path = \"datasets/GSE19804_series_matrix.txt\"\n",
    "preprocessed_file = \"preprocessed_datasets/preprocessed_GSE19804.csv\"\n",
    "output_file = \"preprocessed/preprocessed_with_target_GSE19804.csv\"\n",
    "\n",
    "# Process GSE19804\n",
    "metadata_key = \"tissue\"  # Key for the target variable\n",
    "print(\"Extracting target labels...\")\n",
    "target_labels = extract_target_labels_for_lung_dataset(series_matrix_path, metadata_key)\n",
    "\n",
    "print(len(target_labels))\n",
    "\n",
    "print(\"Merging target labels with preprocessed data...\")\n",
    "merge_target_with_preprocessed(preprocessed_file, target_labels, output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2529e2e5-dda3-463b-acf8-8048856909b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting target labels from '!Sample_characteristics_ch1' using key 'Histopathological diagnostic'...\n",
      "Merging target labels with preprocessed data...\n",
      "Dataset with target labels saved to preprocessed/preprocessed_with_target_GSE4290.csv\n"
     ]
    }
   ],
   "source": [
    "# merge target for tumor dataset\n",
    "series_matrix_path = \"datasets/GSE4290_series_matrix.txt\"\n",
    "preprocessed_file = \"preprocessed_datasets/preprocessed_GSE4290.csv\"\n",
    "output_file = \"preprocessed/preprocessed_with_target_GSE4290.csv\"\n",
    "\n",
    "# Process GSE4290\n",
    "metadata_key = \"Histopathological diagnostic\"  # Key for the target variable\n",
    "print(f\"Extracting target labels from '!Sample_characteristics_ch1' using key '{metadata_key}'...\")\n",
    "target_labels = extract_target_labels_for_tumor_dataset(series_matrix_path, metadata_key)\n",
    "\n",
    "print(\"Merging target labels with preprocessed data...\")\n",
    "merge_target_with_preprocessed(preprocessed_file, target_labels, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46fcb53f-c4f2-4d73-9d15-17d26345428d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting target labels from '!Sample_characteristics_ch1' using key 'disease state'...\n",
      "Merging target labels with preprocessed data...\n",
      "Dataset with target labels saved to preprocessed/preprocessed_with_target_GSE59856.csv\n"
     ]
    }
   ],
   "source": [
    "# merge target for pancreatic dataset\n",
    "series_matrix_path = \"datasets/GSE59856_series_matrix.txt\"\n",
    "preprocessed_file = \"preprocessed_datasets/preprocessed_GSE59856.csv\"\n",
    "output_file = \"preprocessed/preprocessed_with_target_GSE59856.csv\"\n",
    "\n",
    "# Process GSE4290\n",
    "metadata_key = \"disease state\"  # Key for the target variable\n",
    "print(f\"Extracting target labels from '!Sample_characteristics_ch1' using key '{metadata_key}'...\")\n",
    "target_labels = extract_target_labels_for_lung_dataset(series_matrix_path, metadata_key)\n",
    "\n",
    "print(\"Merging target labels with preprocessed data...\")\n",
    "merge_target_with_preprocessed(preprocessed_file, target_labels, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c1a262c-2f7e-4ba7-8b4f-b7e5559d9583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting target labels from '!Sample_characteristics_ch1' using key 'phenotype'...\n",
      "Merging target labels with preprocessed data...\n",
      "Dataset with target labels saved to preprocessed/preprocessed_with_target_GSE27562.csv\n"
     ]
    }
   ],
   "source": [
    "# merge target for breast cancer dataset\n",
    "series_matrix_path = \"datasets/GSE27562_series_matrix.txt\"\n",
    "preprocessed_file = \"preprocessed_datasets/preprocessed_GSE27562.csv\"\n",
    "output_file = \"preprocessed/preprocessed_with_target_GSE27562.csv\"\n",
    "\n",
    "# Process GSE4290\n",
    "metadata_key = \"phenotype\"  # Key for the target variable\n",
    "print(f\"Extracting target labels from '!Sample_characteristics_ch1' using key '{metadata_key}'...\")\n",
    "target_labels = extract_target_labels_for_lung_dataset(series_matrix_path, metadata_key)\n",
    "\n",
    "print(\"Merging target labels with preprocessed data...\")\n",
    "merge_target_with_preprocessed(preprocessed_file, target_labels, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0a9c694-224e-4c55-b1d1-44a30f990caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting target labels from '!Sample_characteristics_ch1' using key 'subtype'...\n",
      "Merging target labels with preprocessed data...\n",
      "575\n",
      "(575, 22283)\n",
      "Dataset with target labels saved to preprocessed/preprocessed_with_target_GSE33315.csv\n"
     ]
    }
   ],
   "source": [
    "# merge target for leukemia dataset\n",
    "series_matrix_path = \"datasets/GSE33315_series_matrix.txt\"\n",
    "preprocessed_file = \"preprocessed_datasets/preprocessed_GSE33315.csv\"\n",
    "output_file = \"preprocessed/preprocessed_with_target_GSE33315.csv\"\n",
    "\n",
    "# Process GSE4290\n",
    "metadata_key = \"subtype\"  # Key for the target variable\n",
    "print(f\"Extracting target labels from '!Sample_characteristics_ch1' using key '{metadata_key}'...\")\n",
    "target_labels = extract_target_labels_for_luekemia_dataset(series_matrix_path, metadata_key)\n",
    "\n",
    "print(\"Merging target labels with preprocessed data...\")\n",
    "merge_target_with_preprocessed(preprocessed_file, target_labels, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e9ddf75-f970-4c14-b991-f3366768001e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the Target column and their counts:\n",
      "Target\n",
      "Malignant                      51\n",
      "Benign                         37\n",
      "Normal                         31\n",
      "Ectopic                        22\n",
      "Post-Surgery                   15\n",
      "Pre-Surgery (aka Malignant)     6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your dataset with the Target column\n",
    "dataset_file = \"preprocessed/preprocessed_with_target_GSE27562.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(dataset_file)\n",
    "\n",
    "# Check if the Target column exists\n",
    "if \"Target\" not in data.columns:\n",
    "    raise ValueError(\"The 'Target' column is not present in the dataset.\")\n",
    "\n",
    "# Find unique values and their counts\n",
    "unique_values = data[\"Target\"].value_counts()\n",
    "\n",
    "# Print unique values and their counts\n",
    "print(\"Unique values in the Target column and their counts:\")\n",
    "print(unique_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "baae5ba3-46ae-44c6-80d2-0e312de9b1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the Target column and their counts:\n",
      "Target\n",
      "7_Other           153\n",
      "1_Hyperdiploid    116\n",
      "3_ETV6_RUNX1       99\n",
      "8_T-ALL            83\n",
      "2_TCF3-PBX1        40\n",
      "4_MLL              30\n",
      "5_Ph               23\n",
      "6_Hypo             23\n",
      "9_CD10CD19          4\n",
      "10_CD34             4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your dataset with the Target column\n",
    "dataset_file = \"preprocessed/preprocessed_with_target_GSE33315.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(dataset_file)\n",
    "\n",
    "# Check if the Target column exists\n",
    "if \"Target\" not in data.columns:\n",
    "    raise ValueError(\"The 'Target' column is not present in the dataset.\")\n",
    "\n",
    "# Find unique values and their counts\n",
    "unique_values = data[\"Target\"].value_counts()\n",
    "\n",
    "# Print unique values and their counts\n",
    "print(\"Unique values in the Target column and their counts:\")\n",
    "print(unique_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5348e3f-2fa1-4833-8e2a-85bef44fd5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the Target column and their counts:\n",
      "Target\n",
      "healthy control                                150\n",
      "pancreatic cancer                              100\n",
      "biliary tract cancer                            98\n",
      "liver cancer                                    52\n",
      "colon cancer                                    50\n",
      "stomach cancer                                  50\n",
      "esophagus cancer                                50\n",
      "benign pancreatic or biliary tract diseases     21\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your dataset with the Target column\n",
    "dataset_file = \"preprocessed/preprocessed_with_target_GSE59856.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(dataset_file)\n",
    "\n",
    "# Check if the Target column exists\n",
    "if \"Target\" not in data.columns:\n",
    "    raise ValueError(\"The 'Target' column is not present in the dataset.\")\n",
    "\n",
    "# Find unique values and their counts\n",
    "unique_values = data[\"Target\"].value_counts()\n",
    "\n",
    "# Print unique values and their counts\n",
    "print(\"Unique values in the Target column and their counts:\")\n",
    "print(unique_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75fc6742-475a-4558-bd4d-2c89351bdc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the Target column and their counts:\n",
      "Target\n",
      "lung cancer               60\n",
      "paired normal adjacent    60\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your dataset with the Target column\n",
    "dataset_file = \"preprocessed/preprocessed_with_target_GSE19804.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(dataset_file)\n",
    "\n",
    "# Check if the Target column exists\n",
    "if \"Target\" not in data.columns:\n",
    "    raise ValueError(\"The 'Target' column is not present in the dataset.\")\n",
    "\n",
    "# Find unique values and their counts\n",
    "unique_values = data[\"Target\"].value_counts()\n",
    "\n",
    "# Print unique values and their counts\n",
    "print(\"Unique values in the Target column and their counts:\")\n",
    "print(unique_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc451f7d-b4d4-4879-9bcf-dcf3dfd8eaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the Target column and their counts:\n",
      "Target\n",
      "glioblastoma         77\n",
      "oligodendroglioma    50\n",
      "astrocytoma          26\n",
      "non-tumor            23\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your dataset with the Target column\n",
    "dataset_file = \"preprocessed/preprocessed_with_target_GSE4290.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(dataset_file)\n",
    "\n",
    "# Check if the Target column exists\n",
    "if \"Target\" not in data.columns:\n",
    "    raise ValueError(\"The 'Target' column is not present in the dataset.\")\n",
    "\n",
    "# Find unique values and their counts\n",
    "unique_values = data[\"Target\"].value_counts()\n",
    "\n",
    "# Print unique values and their counts\n",
    "print(\"Unique values in the Target column and their counts:\")\n",
    "print(unique_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a1a881-59ba-42bd-ae4e-adc814a91716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "Target\n",
      "7_Other           153\n",
      "1_Hyperdiploid    116\n",
      "3_ETV6_RUNX1       99\n",
      "8_T-ALL            83\n",
      "2_TCF3-PBX1        40\n",
      "4_MLL              30\n",
      "5_Ph               23\n",
      "6_Hypo             23\n",
      "9_CD10CD19          4\n",
      "10_CD34             4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Filtered class distribution:\n",
      "Target\n",
      "7_Other           153\n",
      "1_Hyperdiploid    116\n",
      "3_ETV6_RUNX1       99\n",
      "8_T-ALL            83\n",
      "2_TCF3-PBX1        40\n",
      "4_MLL              30\n",
      "5_Ph               23\n",
      "6_Hypo             23\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Filtered dataset saved to preprocessed/filtered_preprocessed_GSE33315.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to dataset with target column\n",
    "dataset_file = \"preprocessed/preprocessed_with_target_GSE33315.csv\"\n",
    "output_file = \"preprocessed/filtered_preprocessed_GSE33315.csv\"\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(dataset_file)\n",
    "\n",
    "# Print original class distribution\n",
    "print(\"Original class distribution:\")\n",
    "print(data[\"Target\"].value_counts())\n",
    "\n",
    "# Keep only classes with at least 20 samples\n",
    "min_count = 20\n",
    "filtered_data = data.groupby(\"Target\").filter(lambda x: len(x) >= min_count)\n",
    "\n",
    "# Save filtered dataset\n",
    "filtered_data.to_csv(output_file, index=False)\n",
    "\n",
    "# Print filtered class distribution\n",
    "print(\"\\nFiltered class distribution:\")\n",
    "print(filtered_data[\"Target\"].value_counts())\n",
    "\n",
    "print(f\"\\nFiltered dataset saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "278dbcb6-a902-4578-b9ad-6a986345c5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "Target\n",
      "Malignant                      51\n",
      "Benign                         37\n",
      "Normal                         31\n",
      "Ectopic                        22\n",
      "Post-Surgery                   15\n",
      "Pre-Surgery (aka Malignant)     6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Filtered class distribution:\n",
      "Target\n",
      "Malignant    51\n",
      "Benign       37\n",
      "Normal       31\n",
      "Ectopic      22\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Filtered dataset saved to preprocessed/filtered_preprocessed_GSE27562.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to dataset with target column\n",
    "dataset_file = \"preprocessed/preprocessed_with_target_GSE27562.csv\"\n",
    "output_file = \"preprocessed/filtered_preprocessed_GSE27562.csv\"\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(dataset_file)\n",
    "\n",
    "# Print original class distribution\n",
    "print(\"Original class distribution:\")\n",
    "print(data[\"Target\"].value_counts())\n",
    "\n",
    "# Keep only classes with at least 20 samples\n",
    "min_count = 20\n",
    "filtered_data = data.groupby(\"Target\").filter(lambda x: len(x) >= min_count)\n",
    "\n",
    "# Save filtered dataset\n",
    "filtered_data.to_csv(output_file, index=False)\n",
    "\n",
    "# Print filtered class distribution\n",
    "print(\"\\nFiltered class distribution:\")\n",
    "print(filtered_data[\"Target\"].value_counts())\n",
    "\n",
    "print(f\"\\nFiltered dataset saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f687a9a-3b6b-4ced-abc1-27a01b284afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "Target\n",
      "glioblastoma         77\n",
      "oligodendroglioma    50\n",
      "astrocytoma          26\n",
      "non-tumor            23\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Filtered class distribution:\n",
      "Target\n",
      "glioblastoma         77\n",
      "oligodendroglioma    50\n",
      "astrocytoma          26\n",
      "non-tumor            23\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Filtered dataset saved to preprocessed/filtered_preprocessed_GSE4290.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to dataset with target column\n",
    "dataset_file = \"preprocessed/preprocessed_with_target_GSE4290.csv\"\n",
    "output_file = \"preprocessed/filtered_preprocessed_GSE4290.csv\"\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(dataset_file)\n",
    "\n",
    "# Print original class distribution\n",
    "print(\"Original class distribution:\")\n",
    "print(data[\"Target\"].value_counts())\n",
    "\n",
    "# Keep only classes with at least 20 samples\n",
    "min_count = 20\n",
    "filtered_data = data.groupby(\"Target\").filter(lambda x: len(x) >= min_count)\n",
    "\n",
    "# Save filtered dataset\n",
    "filtered_data.to_csv(output_file, index=False)\n",
    "\n",
    "# Print filtered class distribution\n",
    "print(\"\\nFiltered class distribution:\")\n",
    "print(filtered_data[\"Target\"].value_counts())\n",
    "\n",
    "print(f\"\\nFiltered dataset saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e98b8947-3580-4920-97af-ba47bb2977c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "Target\n",
      "lung cancer               60\n",
      "paired normal adjacent    60\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Filtered class distribution:\n",
      "Target\n",
      "lung cancer               60\n",
      "paired normal adjacent    60\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Filtered dataset saved to preprocessed/filtered_preprocessed_GSE19804.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to dataset with target column\n",
    "dataset_file = \"preprocessed/preprocessed_with_target_GSE19804.csv\"\n",
    "output_file = \"preprocessed/filtered_preprocessed_GSE19804.csv\"\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(dataset_file)\n",
    "\n",
    "# Print original class distribution\n",
    "print(\"Original class distribution:\")\n",
    "print(data[\"Target\"].value_counts())\n",
    "\n",
    "# Keep only classes with at least 20 samples\n",
    "min_count = 20\n",
    "filtered_data = data.groupby(\"Target\").filter(lambda x: len(x) >= min_count)\n",
    "\n",
    "# Save filtered dataset\n",
    "filtered_data.to_csv(output_file, index=False)\n",
    "\n",
    "# Print filtered class distribution\n",
    "print(\"\\nFiltered class distribution:\")\n",
    "print(filtered_data[\"Target\"].value_counts())\n",
    "\n",
    "print(f\"\\nFiltered dataset saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1ecd0ad-a642-41b5-8209-2422093335d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "Target\n",
      "healthy control                                150\n",
      "pancreatic cancer                              100\n",
      "biliary tract cancer                            98\n",
      "liver cancer                                    52\n",
      "colon cancer                                    50\n",
      "stomach cancer                                  50\n",
      "esophagus cancer                                50\n",
      "benign pancreatic or biliary tract diseases     21\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Filtered class distribution:\n",
      "Target\n",
      "healthy control         150\n",
      "pancreatic cancer       100\n",
      "biliary tract cancer     98\n",
      "liver cancer             52\n",
      "colon cancer             50\n",
      "stomach cancer           50\n",
      "esophagus cancer         50\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Filtered dataset saved to preprocessed/filtered_preprocessed_GSE59856.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to dataset with target column\n",
    "dataset_file = \"preprocessed/preprocessed_with_target_GSE59856.csv\"\n",
    "output_file = \"preprocessed/filtered_preprocessed_GSE59856.csv\"\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(dataset_file)\n",
    "\n",
    "# Print original class distribution\n",
    "print(\"Original class distribution:\")\n",
    "print(data[\"Target\"].value_counts())\n",
    "\n",
    "# Keep only classes with at least 20 samples\n",
    "min_count = 22\n",
    "filtered_data = data.groupby(\"Target\").filter(lambda x: len(x) >= min_count)\n",
    "\n",
    "# Save filtered dataset\n",
    "filtered_data.to_csv(output_file, index=False)\n",
    "\n",
    "# Print filtered class distribution\n",
    "print(\"\\nFiltered class distribution:\")\n",
    "print(filtered_data[\"Target\"].value_counts())\n",
    "\n",
    "print(f\"\\nFiltered dataset saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335aff45-1de5-41e7-b5c9-b4e0eda5ec1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
